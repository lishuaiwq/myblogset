---
title: 海量数据面试题
date: 2018-05-14 07:18:40
tags: 
categories: 数据结构随笔
---
## 给一个超过100G大小的log file,log中村着IP地址，设计算法找到出现次数最多的IP地址？


### 问题分析

- 首先从题目可以看出来主要的问题是100G的文件容量过大内存无法一次性放下
- 其次我们可以看到需要统计IP出现的次数，一旦出现统计次数这种关键字眼我们就应该想到<key,value>这种数据结构，所在在这里我们用HashTable.

### 解决办法

- 首先使用哈希切割将其分成1000分文件，即将每个IP地址讲过散列函数以后放到于其对应的文件中，这样做的好处首先是将大文件拆分成了小文件，其次将相同的IP地址放在了一个文件中。那么为什么切成1000份呢而不是100份呢？因为哈希切割是不均匀的，切割后的文件大小不一致，如果我们分成了1000份，平均下来每个大小也就100Mb,即时不均匀，文件也不会太大。
```c++
hashfunc(ip)%1000;//哈希分割,将这些ip放入对应的文件
```
- 然后根据哈希表去统计每个文件中出现次数最多的Ip地址，然后从10个文件中，找出出现数字最多的Ip,即就是我们要找的答案
```c++
hashtable[ip]++;//统计每个文件中ip出现的次数
```

### 问题延伸

- 如果我们要找前出现次数最多的前100个IP的话怎么解决呢?
- 答：使用Top k解决策略，用100个IP直接建一个小堆，然后从每个文件中每个IP出现的次数和堆顶的元素比较，如果比其大的话，那么将其放入堆中，最后将所有文件遍历完，则堆中的元素就是出现次数最多的前100个IP
---


## 与上题条件相同，如果找到Tok K的IP？如何直接用Linux系统命令直接实现呢？

----

## 给定100亿个整数，设计算法找到只出现一次的整数？


### 问题分析
- 首先看到100亿个整数我们第一想法会想到位图吗，没错这个题是用位图解决
- 可是位图单纯的一位只能表示这个数字在不在，没有办法表示他出现了几次，所以我们在这里使用两位来表示一个数的状态，即有没有出现过、出现了几次、这种状态由你自己规定是01 10 00之类的。
- 之后遍历位图找到出现一次的数就可以了

### 解决办法

- 下面主要给出伪代码的实现
```c++
#include<iostream>
#include<vector>
using namespace std;
class TwoBitSap
{
public:
	bool TestBit(size_t index, size_t num)
	{
		return _bits[index] & (1 << num);//判断两个位是0还是1，_bits[index]表示在第几个size_t当中
	}
	void Add(size_t x)
	{
		size_t index =x/ 16;
		size_t num = x% 16 * 2;//找到其两位
		bool  first=TestBit(index, num);
		bool second=TestBit(index, num + 1);
		if (first == false && second == false)//表示一次都没有出现过
		{
			;
		}
		else if (first==false&&second==true)//出现过1次
		{
			;//表示出现过一次比如01表示出现了一次了，那么将其改为10，
		}
		//后续代码只需要从位图中找到01就表示只出现了一次
	}
protected:
	vector<size_t> _bits;
};
```
### 问题延伸
- 如果不允许使用位图的话，我们可以继续使用哈希切割的思想
---
## 给两个文件，分别有100亿个整数，我们只有1G内存，如何找到这两个文件的交集？

### 问题分析
- 又是上百亿整数所以这个题我们还是使用位图
- 将两个文件的整数全部映射到两个位图当中去
- 因为我们要求得是交集所有我们将两个位图按位与最后得到的结果就是他们的交集

### 问题延伸
- 如果要找他们的并集的话我们只需要按位或就可以了
- 那么如果要找他们的差集呢？则异或就可以很好的解决问题
---
## 1个文件有100亿个int，1G内存，设计算法找到出现次数不超过两次的所有整数集？
---

### 问题分析
- 这个题和第三题的解题方法思路几乎一样这里就不多阐述了。

---
## 给两个文件，分别有100亿个查询，有1G内存，如何找到两个文件的交集？分别给出精确的算法和近似的算法？

### 问题分析
- 运用哈希切割的思想，将两个文件分别运用同一个散列函数切割成小块文件，然后两个两个文件对应再运用set去找在不在

### 解决方法

![](https://i.imgur.com/6tixTZZ.jpg)

---

## 如何扩展布隆过滤器使得它支持删除元素的操作？

### 问题分析

- 首先我们知道布隆过滤器不支持删除，因为多个key可能映射在同一个位置，如果你根据其中的一个key贸然的删除这个位的话，那么其他的key是不是也就找不到了。
- 所以如果我们要对布隆过滤器进行删除的话，我们需要对每个位的引用个数进行计数

---

## 给你上千个文件，每个文件大小1K-100M。给n个词，设计算法对每个词找到所有包含它的文件，你只有100k的内存

### 问题分析
- 倒排索引，了解搜索引擎底层，这里就略了！



